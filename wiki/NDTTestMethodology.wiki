#summary Description of the NDT test methodology

=NDT Test Methodology= 

== Abstract == 

The Network Diagnostic Tool (NDT) is a client/server program that provides network configuration and performance testing to a user's computer. The NDT is designed to identify both performance problems and configuration problems. Performance problems affect the user experience, usually causing data transfers to take longer than expected. These problems are usually solved by tuning various TCP (Transmission Control Protocol) network parameters on the end host. Configuration problems also affect the user experience; however, tuning will not improve the end-to-end performance. The configuration fault must be found and corrected to change the end host behavior. The NDT is providing enough information to accomplish these tasks. This document describes how these information is gathered and what NDT is and is not capable of answering.

== Table of Contents ==

<wiki:toc max_depth="3" />

== Introduction ==

The NDT is a typical memory to memory client/server test device. Throughput measurements closely measure the network performance, and ignore the disk I/O effects. The real strength is in the advanced diagnostic features that are enabled by the kernel data automatically collected by the web100 monitoring infrastructure.  This data is collected during the test (at 5 msec increments) and analyzed after the test completes to determine what, if anything, impacted the test. One of the MAJOR issues facing a commodity Internet users is the performance limiting host configuration settings for the Windows XP operating system. To illustrate this, a cable modem user with basic service (15 Mbps download) would MAX out at 13 Mbps with a 40 msec RTT delay. Thus unless the ISP proxies content, the majority of traffic will be limited by the clients configuration and NOT the ISP's infrastructure.  The NDT server can detect and report this problem, saving consumers and ISP's dollars by allowing them to quickly identify where to start looking for a problem. The FCC really needs to understand this message, or we will not be as effective as we need to be.

The NDT operates on any client with a Java-enabled Web browser; further:
 * What it can do:
   * Positively state if Sender, Receiver, or Network is operating properly
   * Provide accurate application tuning info
   * Suggest changes to improve performance
 * What it can’t do:
   * Tell you where in the network the problem is
   * Tell you how other servers perform
   * Tell you how other clients will perform

== Performed tests ==

=== Middlebox Test ===

The middlebox test is a short throughput test from the server to the client with a limited CWND ([http://en.wikipedia.org/wiki/Congestion_window congestion window] - one of the factors that determines the number of bytes that can be outstanding at any time) to check for a duplex mismatch condition. Moreover, this test uses a pre-defined MSS value to check if any intermediate node will modify its connection settings.

A detailed description of all of the MID protocol messages can be found in the [NDTProtocol#Middlebox_test NDT Protocol document].

As a first step the server binds an ephemeral port and notify the client about this port number. The server also sets MSS on this port to 1456 (a strange value that it is unlikely a routers will have been tested with, so this also tests that they can handle such weird MSS sizes).

Next, the client connects to the server's ephemeral port. When the connection is successfully established, the server sets the maximum value of the congestion window for this connection to `2 * (The current maximum segment size (MSS))`.

In the next step the server starts a 5 seconds throughput test using the newly created connection. The NDT server sends packets as fast as possible (i.e. without any delays) during the test. These packets are written using the buffer of the following size: `(The current maximum segment size (MSS))`. If such buffer cannot be used, then the server uses a 8192 Byte one. The buffer contains a pre-generated pseudo random data (including only US-ASCII printable characters).

The server can temporarily stop sending packets when the following formula is fulfilled:
{{{
BUFFER_SIZE * 16 < ((Next Sequence Number To Be Sent) - (Oldest Unacknowledged Sequence Number) - 1)
}}}

The both `"Next Sequence Number To Be Sent"` and `"Oldest Unacknowledged Sequence Number"` values are obtained from the connection with the help of the [http://www.web100.org/ web100] library.

When the 5 seconds throughput test is over, the server sends the following results to the client:

|| CurMSS || The current maximum segment size (MSS), in octets.||
|| !WinScaleSent || The value of the transmitted window scale option if one was sent; otherwise, a value of -1. ||
|| !WinScaleRcvd || The value of the received window scale option if one was received; otherwise, a value of -1. ||

Next, the client sends its calculated throughput value to the server. The throughput value is calculated by taking the transmitted bytes over the duration of the test. This value, in Bps, is then converted to kbps. This can be shown by the following formula:
{{{
THROUGHPUT_VALUE = (TRANSMITTED_BYTES / TEST_DURATION_SECONDS) * 8 / 1000
}}}

=== Simple Firewall Test ===

The simple firewall test tries to find out any firewalls between the NDT client and the NDT server that will prevent connections to an ephemeral port numbers. The test is performed in both directions (i.e. the NDT client is trying to connect to the NDT server and the NDT server is trying to connect to the NDT client).

A detailed description of all of the SFW protocol messages can be found in the [NDTProtocol#Simple_firewall_test NDT Protocol document].

As a first step both NDT components (the server and the client) bind an ephemeral port and notify the second component about this port number. In the second step both NDT components are executing in parallel:
 # The client is trying to connect to the server's ephemeral port and send a TEST_MSG message containing a pre-defined string "Simple firewall test" of length 20 using the newly created connection.
 # The server is trying to connect to the client's ephemeral port and send a TEST_MSG message containing a pre-defined string "Simple firewall test" of length 20 using the newly created connection.

Both client and server are waiting for a valid connection a limited amount of time. If the MaxRTT or MaxRTO is greater than 3 seconds, than the time limit in the SFW test is 3 seconds. Otherwise the time limit in the SWF test is 1 second.

The test is finished after the connection will be accepted or the time limit will be exceeded. If the time limit is exceeded, the firewall probably exists somewhere on the end-to-end path. If there is a connection and the pre-defined string is properly transferred, then there is probably no firewall on the end-to-end path (technically there still could be a firewall with a range of opened ports or a special rules that allowed this one particular connection to the ephemeral port). The third possibility is that there is a successful connection, but the expected pre-defined string is not transferred. This case does not adjudicate about the firewall existence.

In the last step the server sends its results to the client.

The possible simple firewall test result codes:

|| *Value* || *Description* ||
|| "0" || Test was not started ||
|| "1" || Test was successful (i.e. connection to the ephemeral port was possible and the pre-defined string was received) ||
|| "2" || There was a connection to the ephemeral port, but the pre-defined string was not received ||
|| "3" || There was no connection to the ephemeral port within the specified time ||

=== C2S Throughput Test ===

The C2S throughput test tests the achievable network bandwidth from the client to the server by performing a 10 seconds memory-to-memory data transfer.

A detailed description of all of the C2S protocol messages can be found in the [NDTProtocol#C2S_throughput_test NDT Protocol document].

As a first step the server binds an ephemeral port and notify the client about this port number.

Next, the client connects to the server's ephemeral port. When the connection is successfully established, the server initializes the following routines:
 * libpcap routines to perform packet trace used by the [NDTTestMethodology#Bottleneck_Link_Detection Bottleneck Link Detection] algorithm.
 * [NDTDataFormat#tcpdump_trace tcpdump trace] to dump all packets sent during the [NDTTestMethodology#C2S_Throughput_Test C2S throughput test] on the newly created connection. This tcpdump trace dump is only started when the `-t, --tcpdump` options are set.
 * [NDTDataFormat#web100_snaplog_trace web100 snaplog trace] to dump web100 kernel MIB variables' values written in a fixed time (default is 5 msec) increments during the [NDTTestMethodology#C2S_Throughput_Test C2S throughput test] for the newly created connection. This snaplog trace dump is only started when the `--snaplog` option is set.

In the next step the client starts a 10 seconds throughput test using the newly created connection. The NDT client sends packets as fast as possible (i.e. without any delays) during the test. These packets are written using the 8192 Byte buffer containing a pre-generated pseudo random data (including only US-ASCII printable characters).

When the 10 seconds throughput test is over, the server sends its calculated throughput value to the client. The throughput value is calculated by taking the transmitted bytes over the duration of the test. This value, in Bps, is then converted to kbps. This can be shown by the following formula:
{{{
THROUGHPUT_VALUE = (TRANSMITTED_BYTES / TEST_DURATION_SECONDS) * 8 / 1000
}}}

=== S2C Throughput Test ===

The S2C throughput test tests the achievable network bandwidth from the server to the client by performing a 10 seconds memory-to-memory data transfer.

A detailed description of all of the S2C protocol messages can be found in the [NDTProtocol#S2C_throughput_test NDT Protocol document].

As a first step the server binds an ephemeral port and notify the client about this port number.

Next, the client connects to the server's ephemeral port. When the connection is successfully established, the server initializes the following routines:
 * libpcap routines to perform packet trace used by the [NDTTestMethodology#Bottleneck_Link_Detection Bottleneck Link Detection] algorithm.
 * [NDTDataFormat#tcpdump_trace tcpdump trace] to dump all packets sent during the [NDTTestMethodology#S2C_Throughput_Test S2C throughput test] on the newly created connection. This tcpdump trace dump is only started when the `-t, --tcpdump` options are set.
 * [NDTDataFormat#web100_snaplog_trace web100 snaplog trace] to dump web100 kernel MIB variables' values written in a fixed time (default is 5 msec) increments during the [NDTTestMethodology#S2C_Throughput_Test S2C throughput test] for the newly created connection. This snaplog trace dump is only started when the `--snaplog` option is set.

In the next step the server starts a 10 seconds throughput test using the newly created connection. The NDT server sends packets as fast as possible (i.e. without any delays) during the test. These packets are written using the 8192 Byte buffer containing a pre-generated pseudo random data (including only US-ASCII printable characters).

When the 10 seconds throughput test is over, the server sends to the client its calculated throughput value, amount of unsent data in the socket send queue and overall number of sent bytes. The throughput value is calculated by taking the transmitted bytes over the duration of the test. This value, in Bps, is then converted to kbps. This can be shown by the following formula:
{{{
THROUGHPUT_VALUE = (TRANSMITTED_BYTES / TEST_DURATION_SECONDS) * 8 / 1000
}}}

Additionally, at the end of the S2C throughput test, the server also takes a web100 snapshot and sends all the web100 data variables to the client.

== Specific detection algorithms ==

All of the following detection algorithms are run during the [NDTTestMethodology#S2C_Throughput_Test S2C throughput test]. This means, that the NDT server is the sender and the client is the receiver during all these heuristics. The only exception is the [NDTTestMethodology#Bottleneck_Link_Detection Bottleneck Link Detection] algorithm, which observes all test traffic during both the C2S and the S2C throughput tests.

=== Bottleneck Link Detection ===

The NDT can find the answer to the question "What is the slowest link in the end-2-end path?" by doing the following:
 * monitoring packet arrival times using libpcap routine
 * using TCP dynamics to create packet pairs
 * quantizing results into link type bins (no fractional or bonded links)

The NDT uses packet dispersion techniques; e.g., it measures the inter-packet arrival times for all data and ACK packets sent or received. It also knows the packet size, so it can calculate the speed for each pair of packets sent or received. The results are then quantized, meaning that the NDT doesn’t recognize fractional link speed (Ethernet, T3, or FastE). It also wouldn’t detect bonded Etherchannel interfaces.

The speed calculation is done using the following formula:
{{{
bits/time
}}}

where:
 * *bits* - the number of bits in the current packet
 * *time* - the time in 10^-6 seconds from the last packet arrival

It means that the calculated speed is in mbits/second. The results are then quantized into the following beans:

 * 0 < bits/time <= 0.01 - *RTT*
 * 0.01 < bits/time <= 0.064 - *Dial-up Modem*
 * 0.064 < bits/time <= 1.5 - *Cable/DSL modem*
 * 1.5 < bits/time <= 10 - *10 Mbps Ethernet or !WiFi 11b subnet*
 * 10 < bits/time <= 40 - *45 Mbps T3/DS3 or !WiFi 11 a/g subnet*
 * 40 < bits/time <= 100 - *100 Mbps Fast Ethernet subnet*
 * 100 < bits/time <= 622 - *a 622 Mbps OC-12 subnet*
 * 622 < bits/time <= 1000 - *1.0 Gbps Gigabit Ethernet subnet*
 * 1000 < bits/time <= 2400 - *2.4 Gbps OC-48 subnet*
 * 2400 < bits/time <= 10000 - *10 Gbps 10 Gigabit Ethernet/OC-192 subnet*
 * bits cannot be determined - *Retransmissions*
 * otherwise - ?

=== Duplex Mismatch Detection ===

The NDT contains two heuristics for the duplex mismatch detection.

A duplex mismatch is detected by the Old Duplex-Mismatch algorithm when all of the following conditions are met:
 * The [NDTTestMethodology#'Congestion_Limited'_state_time_share 'Congestion Limited' state time share] *is greater than 90%*
 * The [NDTTestMethodology#Speed_estimate speed estimate] *is greater than 2000000 bits per second*
 * The number of segments transmitted containing at least some retransmitted data *is greater than 2 per second*
 * The maximum slow start threshold, excluding the initial value, *is greater than 0*
 * The cumulative time of the expired retransmit timeouts RTO *is greater than 1% of the total test time*
 * (link > 2) (*WARNING: this condition is always true*)
 * The throughput speed measured during the MID test (with a limited CWND) *is greater than* the throughput speed measured during the S2C test
 * The multi-test mode must be disabled (so the `-m, --multiple` options cannot be set)
 * The throughput speed measured during the C2S test *is greater than* the throughput speed measured during the S2C test

If all of the above conditions are met except the last one, then the NDT assumes that a new duplex mismatch detection algorithm discovers the problem.

The new duplex mismatch detection algorithm also discovers the problem when all of the following conditions are met:
 * The throughput speed measured during the S2C test *is greater than 50000000 bits per second*
 * The [NDTTestMethodology#Web100_measured_speed web100 measured speed] *is less than 5000000 bits per second*
 * The [NDTTestMethodology#'Receiver_Limited'_state_time_share 'Receiver Limited' state time share] *is greater than 90%*
 * The proportion of the number of multiplicative downward congestion window adjustments to the total number of segments sent *is less than 1%*

=== Link Type Detection Heuristics ===

The following link type detection heuristics are run only when there is no duplex mismatch condition detected and the [NDTTestMethodology#Web100_measured_speed web100 measured speed] is the same or smaller than the [NDTTestMethodology#Speed_estimate speed estimate] (which is a correct situation).

==== DSL/Cable modem ====

The link is treated as a DSL/Cable modem when all of the following conditions are met:
 * The cumulative time spent in the 'Sender Limited' state *is less than 0.6 ms*
 * The number of transitions into the 'Sender Limited' state *is 0*
 * The [NDTTestMethodology#Web100_measured_speed web100 measured speed] *is less than 2000000 bits per second*
 * The [NDTTestMethodology#Web100_measured_speed web100 measured speed] *is less than* [NDTTestMethodology#Speed_estimate speed estimate]

==== IEEE 802.11 (!WiFi) ====

The link is treated as a wireless one when all of the following conditions are met:
 * The heuristic for DSL/Cable modem link *gives negative results*
 * The cumulative time spent in the 'Sender Limited' state *is 0 ms*
 * The [NDTTestMethodology#Web100_measured_speed web100 measured speed] *is less than 5000000 bits per second*
 * The [NDTTestMethodology#Speed_estimate speed estimate] *is greater than 52428800 bits per second*
 * The number of transitions into the 'Receiver Limited' state *is the same* as the number of transitions into the 'Congestion Limited' state
 * The [NDTTestMethodology#'Receiver_Limited'_state_time_share 'Receiver Limited' state time share] *is greater than 90%*

==== Ethernet link (Fast Ethernet) ====

The link is treated as an Ethernet link (Fast Ethernet) when all of the following conditions are met:
 * The heuristics for !WiFi and DSL/Cable modem links *give negative results*
 * The [NDTTestMethodology#Web100_measured_speed web100 measured speed] *is less than 9500000 bits per second*
 * The [NDTTestMethodology#Web100_measured_speed web100 measured speed] *is greater than 3000000 bits per second*
 * The S2C throughput test measured speed *is less than 9500000 bits per second*
 * The proportion of the number of multiplicative downward congestion window adjustments to the total number of segments sent *is less than 1%*
 * The proportion of the duplicate ACKs received to the overall number of valid pure ACKs received *is less than 3.5%*

=== Faulty Hardware Link Detection ===

A bad cable (faulty hardware link) is detected when all of the following conditions are met:
 * The [NDTTestMethodology#Packet_loss packet loss] multiplied by 100 and divided by the [NDTTestMethodology#Total_test_time_in_seconds total test time in seconds] *is greater than 15*
 * The [NDTTestMethodology#'Congestion_Limited'_state_time_share 'Congestion Limited' state time share] divided by the [NDTTestMethodology#Total_test_time_in_seconds Total test time in seconds] *is greater than 0.6* (*WARNING: this condition cannot be met*)
 * The proportion of the number of multiplicative downward congestion window adjustments to the total number of segments sent *is less than 1%*
 * The maximum slow start threshold, excluding the initial value, *is greater than 0*

=== Full/Half Link Duplex Setting ===

A half duplex is detected when all of the following conditions are met:
 * The [NDTTestMethodology#'Receiver_Limited'_state_time_share 'Receiver Limited' state time share] *is greater than 95%*
 * The number of transitions into the 'Receiver Limited' state *is greater than 30 per second*
 * The number of transitions into the 'Sender Limited' state *is greater than 30 per second*

=== Normal Congestion Detection ===

A normal congestion is detected when all of the following conditions are met:
 * The [NDTTestMethodology#'Congestion_Limited'_state_time_share 'Congestion Limited' state time share] *is greater than 2%*
 * The duplex mismatch condition heuristic *gives negative results*
 * The maximum window advertisement received *is greater than* the maximum congestion window used during Slow Start

=== Firewall Detection ===

A firewall is detected when the connection to the ephemeral port was unsuccessful in the specified time. The results for the server are independent from the results for the client.

Please note, that the NDT states that the node is only *probably* behind a firewall. The connection can be unsuccessful from a variety of other reasons.

=== NAT Detection ===

The Network Address Translation (NAT) box is detected by the comparison of the client/server IP addresses visible from the server and the client boxes.

When the server IP address visible to the client is different from the one known to the server itself, then the NAT box is modifying the server's IP address.

Analogically, when the client IP address visible to the server is different from the one known to the client itself, then the NAT box is modifying the client's IP address.

=== MSS Modifications ===

The NDT checks packet size preservation by comparing the final value of the MSS variable in the MID test.

When this variable's value is different than 1456, then the network middlebox had to change it during the test.

When this variable's value is 1456, then it means that the packet size is preserved End-to-End.

== Computed variables ==

=== Total test time ===

The total test time is computed using the following formula:

{{{
SndLimTimeRwin + SndLimTimeCwnd + SndLimTimeSender
}}}

where:
 * *!SndLimTimeRwin* - The cumulative time spent in the 'Receiver Limited' state
 * *!SndLimTimeCwnd* - The cumulative time spent in the 'Congestion Limited' state
 * *!SndLimTimeSender* - The cumulative time spent in the 'Sender Limited' state

The total test time is kept in 10^-6 seconds.

=== Total test time in seconds ===

The total test time in seconds is computed using the following formula:

{{{
TotalTestTime/1000000
}}}

where:
 * *!TotalTestTime* - [NDTTestMethodology#Total_test_time Total test time]

=== Web100 measured speed ===

The web100 measured speed is computed using the following formula:

{{{
DataBytesOut / TotalTestTime * 8
}}}

where:
 * *!DataBytesOut* - The number of octets of data contained in transmitted segments, including retransmitted data.
 * *!TotalTestTime* - [NDTTestMethodology#Total_test_time Total test time]

The web100 measured speed is kept in mbits per second.

=== Packet loss ===

The packet loss proportion is computed using the following formula:

{{{
CongestionSignals/PktsOut
}}}

where:
 * *!CongestionSignals* - The number of multiplicative downward congestion window adjustments due to all forms of congestion signals
 * *!PktsOut* - The total number of segments sent

When the `CongestionSignals` value is *0*, then the packet loss proportion is set to the following values:
 * *0.0000000001* - if a link type detected by the Bottleneck Link Detection algorithm using the *Client --> Server data packets*' inter-packet arrival times is faster than a 100 Mbps Fast Ethernet subnet.
 * *0.000001* - otherwise

=== Packets arriving out of order ===

The out of order packets proportion is computed using the following formula:

{{{
DupAcksIn/AckPktsIn
}}}

where:
 * *!DupAcksIn* - The number of duplicate ACKs received
 * *!AckPktsIn* - The number of valid pure ACKs received

=== Average round trip time (Latency/Jitter) ===

The average round trip time is computed using the following formula:

{{{
SumRTT/CountRTT
}}}

where:
 * *SumRTT* - The sum of all sampled round trip times
 * *CountRTT* - The number of round trip time samples

The average round trip time is kept in milliseconds.

=== Average RTT in seconds ===

The average round trip time in seconds is computed using the following formula:

{{{
AvgRTT/1000
}}}

where:
 * *AvgRTT* - [NDTTestMethodology#Average_round_trip_time_(Latency/Jitter) Average round trip time (Latency/Jitter)]

=== Speed estimate ===

The speed estimate is computed using the following formula:

{{{
(CurrentMSS / (AvgRTTSec * sqrt(PktsLoss))) * 8 / 1024 / 1024
}}}

where:
 * *CurrentMSS* - The current maximum segment size (MSS), in octets
 * *AvgRTTSec* - [NDTTestMethodology#Average_RTT_in_seconds Average RTT in seconds]
 * *!PktsLoss* - [NDTTestMethodology#Packet_loss Packet loss]

The speed estimate is kept in mbits per second.

=== 'Congestion Limited' state time share ===

The 'Congestion Limited' state time share is computed using the following formula:

{{{
SndLimTimeCwnd/TotalTestTime
}}}

where:
 * *!TotalTestTime* - [NDTTestMethodology#Total_test_time Total test time]
 * *!SndLimTimeCwnd* - The cumulative time spent in the 'Congestion Limited' state

=== 'Receiver Limited' state time share ===

The 'Receiver Limited' state time share is computed using the following formula:

{{{
SndLimTimeRwin/TotalTestTime
}}}

where:
 * *!TotalTestTime* - [NDTTestMethodology#Total_test_time Total test time]
 * *!SndLimTimeRwin* - The cumulative time spent in the 'Receiver Limited' state


=== 'Sender Limited' state time share ===

The 'Sender Limited' state time share is computed using the following formula:

{{{
SndLimTimeSender/TotalTestTime
}}}

where:
 * *!TotalTestTime* - [NDTTestMethodology#Total_test_time Total test time]
 * *!SndLimTimeSender* - The cumulative time spent in the 'Sender Limited' state